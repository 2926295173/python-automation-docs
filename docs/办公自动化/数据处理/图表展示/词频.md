

> 利用 `Python` 生成词云图

![Python](https://img.shields.io/badge/Python-3.7+-blue)
![Wordcloud](https://img.shields.io/badge/wordcloud-1.8.0-brightgreen)
![Pandas](https://img.shields.io/badge/pandas-1.1.1-red)
![Matplotlib](https://img.shields.io/badge/matplotlib-3.3.2-blue)
![Jieba](https://img.shields.io/badge/jieba-0.42.1-green)

`词频分析` 实际上是一种条形图，横竖条形图视情况而定 ！！

![诠释词云](../images/诠释词频.jpg ':size=50%')

## 安装依赖库

我们需要安装一些必要的依赖来让 `Python` 正常工作。

```shell
pip install Pandas
pip install Jieba
pip install Wordcloud
pip install Matplotlib
```

## 准备数据
我们需要一些用以分析的数据集，这些数据集一般可以是`Execl`表格文件、`csv`表格文件、甚至是 `txt` 文本文件，或者从
我们的`数据库`中获取，比如 `Mysql`、`MongoDB` 等等。

这里准备了一份 `Excel`表格作为我们的初始数据集 [关键词提取.xlsx](./files/关键词提取.xlsx)

## 开始码字

> 最终代码

```python
# -*- coding: utf-8 -*-
import os
import jieba
from collections import Counter
import json
import matplotlib.pyplot as plt
import pandas as pd
from matplotlib import ticker

def read_content(df):
    contents = ','
    for i in range(len(df)):
        l_con = str(df["评论内容"][i])
        i_con = str(df["追加评论"][i]) if str(df["追加评论"][i]) != "nan" else ""
        # print("评论: ",l_con)
        # print("追加评论: ",i_con)
        print("评论+追评: ", l_con + i_con)
        contents += l_con + i_con

    return {'contents': contents}


def txt2plt(contents, index):
    
    # 字体风格
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['font.family'] = 'sans-serif'
    
    # 虽然没有屏蔽词文件，但是我们可以用列表的形式过滤掉一些词
    _words = [x for x in jieba.cut(contents) if
                    len(x) >= 2 and x not in [
                        "这里", "就是", "无用", "的词"]]

    c = Counter(_words).most_common(15)  # 取15组
    print(json.dumps(c, ensure_ascii=False))

    name_list = [x[0] for x in c]  # X轴的值
    num_list = [x[1] for x in c]  # Y轴的值
    plt.barh(name_list, num_list, alpha=0.6)
    plt.xlabel('次数')
    plt.ylabel('词语')
    plt.title(f'{index} - 文本分词统计', loc='center', fontsize='15',fontweight='bold')
    plt.savefig(f"./{index}.jpg")
    plt.show()


f = pd.ExcelFile('关键词提取.xlsx')

data = pd.DataFrame()
for i in f.sheet_names:
    df = pd.read_excel('关键词提取.xlsx', sheet_name=i)
    content_dict = read_content(df)
    txt2plt(content_dict['contents'], i)
```


