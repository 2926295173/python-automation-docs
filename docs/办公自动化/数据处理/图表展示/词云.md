![logo](https://www.easyicon.net/api/resizeApi.php?id=1214577&size=96)

> 利用 `Python` 生成词云图

![Python](https://img.shields.io/badge/Python-3.7+-blue)
![Wordcloud](https://img.shields.io/badge/wordcloud-1.8.0-brightgreen)
![Pandas](https://img.shields.io/badge/pandas-1.1.1-red)
![Matplotlib](https://img.shields.io/badge/matplotlib-3.3.2-blue)
![Jieba](https://img.shields.io/badge/jieba-0.42.1-green)

`词云图`能更直接美观的呈现出文本中不同词语出现的次数，也就是`词频`，
所以人们总是热衷于用这样的`词云图`来诠释图表的意义:
![诠释词云](../images/诠释词云.jpg ':size=36%')

确实，这种展示图表的方式的确能够引起大众的共鸣，直接、美观、有趣 ！！

## 安装依赖库

我们需要安装一些必要的依赖来让 `Python` 正常工作。

```shell
pip install Pandas
pip install Jieba
pip install Wordcloud
pip install Matplotlib
```

## 准备数据
我们需要一些用以分析的数据集，这些数据集一般可以是 `Execl`表格文件、`csv`表格文件、甚至是 `txt` 文本文件，或者从
我们的`数据库`中获取，比如 `Mysql`、`MongoDB` 等等。

这里准备了一份 Excel表格作为我们的初始数据集 [关键词提取.xlsx](./files/关键词提取.xlsx)


## 开始码字

### 读取数据集
```python
# -*- coding: utf-8 -*-
import jieba
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import pandas as pd
import os

def read_content(df):
    w_contents = []
    h_contents = []
    for i in range(len(df)):
        w_con = str(df["问题内容"][i])
        h_con = str(df["回答内容"][i])
        print("问题内容",w_con)
        print("回答内容",h_con)
        w_contents.append(w_con)
        h_contents.append(h_con)
    return {'w_contents': w_contents,'h_contents':h_contents}

f = pd.ExcelFile('../问大家词频统计.xlsx')
 
data = pd.DataFrame()
for i in f.sheet_names:
    df = pd.read_excel('../问大家词频统计.xlsx', sheet_name=i)
    print(i.split('｜')[-1])
    content_dict = read_content(df)
    print(content_dict)
```

读取到内容如下:
```text
问题内容 这个和暗影有啥区别啊？为啥都在推荐暗影
回答内容 暗影上游戏比光影强一些，游戏性能比光影强
问题内容 这个和暗影有啥区别啊？为啥都在推荐暗影
回答内容 。。。。
问题内容 这个和暗影有啥区别啊？为啥都在推荐暗影
回答内容 暗影比这更游戏本
问题内容 这个和暗影有啥区别啊？为啥都在推荐暗影
回答内容 推荐暗影，当个等等党，新的暗影要出了。暗影比光影好点。
问题内容 这个和暗影有啥区别啊？为啥都在推荐暗影
回答内容 不懂
问题内容 这个和暗影有啥区别啊？为啥都在推荐暗影
回答内容 不懂，但是好几次开不开机，客服说是静电原因
问题内容 打CF   CSGO   吃鸡怎么样啊，卡不卡啊？CAD画图啥的没问题吧。
回答内容 贼卡，建议别买
问题内容 打CF   CSGO   吃鸡怎么样啊，卡不卡啊？CAD画图啥的没问题吧。
回答内容 微卡，
问题内容 打CF   CSGO   吃鸡怎么样啊，卡不卡啊？CAD画图啥的没问题吧。
回答内容 没有
问题内容 室内设计用i7还是i5ACD还有其他设计软件好用嘛？
回答内容 不要买！才用两个月各种死机！感觉用不到一年就会报废。
问题内容 室内设计用i7还是i5ACD还有其他设计软件好用嘛？
回答内容 毕竟是光影精灵不是暗影精灵，建议买暗影精灵
问题内容 室内设计用i7还是i5ACD还有其他设计软件好用嘛？
回答内容 别买
问题内容 室内设计用i7还是i5ACD还有其他设计软件好用嘛？
回答内容 别买  卡了  不到一个月
问题内容 室内设计用i7还是i5ACD还有其他设计软件好用嘛？
回答内容 不太好吧
问题内容 有提示升更新或者激活Windows吗
回答内容 有的开机就会提示
问题内容 有提示升更新或者激活Windows吗
```

> 这说明我们可以正常的读取到初使数据集中的数据，有了一个好的开头 ！！

### 设置分词

在展示词云图之前，我们需要将文本内容进行分词，这里用到了 `jieba` 组件，`jieba`组件分词相对准确且支持多种分词模式，
在此场景中可能是最佳选择。

```python
def wordCloudShow(contents,index,stopwords,font):
    # 准确分词
    contents_after_split = jieba.cut(str(contents), cut_all=False) 
    
    # 只获取长度大于等于2的字符，也就是单个文字不构成分析条件
    words = ' '.join([i for i in contents_after_split if len(i) >= 2])

    # 设置屏蔽词，引入屏蔽词文件
    STOPWORDS = set(map(str.strip, open(stopwords,encoding="utf-8").readlines()))

    
    # 导入背景图
    bg_image = plt.imread(f'../pic/1.jpg')
    
    # 设置词云参数，参数分别表示：画布宽高、背景颜色、背景图形状、字体,屏蔽词、最大词的字体大小
    wc = WordCloud(background_color='white',
                   mask=bg_image,
                   font_path=font,
                   stopwords=STOPWORDS,
                   max_font_size=200,
                   random_state=100)

    # 将分词后数据传入云图
    wc.generate_from_text(words)
    plt.imshow(wc)
    plt.axis('off')  # 不显示坐标轴
    plt.show() # show 出来

    # 保存结果到本地
    wc.to_file(f'../../词云图/问题内容/{index}.jpg')
```

可以看到，在此方法中我们将传入 
`content` (文本内容)、 
`index` (生成图片的序号)、 
`stopwords` (屏蔽词)、
`font` (指定字体)

### `stopwords`

`屏蔽词`文件，这里我们以 `stopwords` 命名，顾名思义就是我们不希望一些无意义的，对文本分析不用的词出现在我们展示的词云图上，
需要将它们过滤屏蔽掉。

`WordCloud` 对象中提供了这么一个参数，可以自定义 `stopwords` 过滤掉一些无意义的词。

比如`什么`、`亲`、`该用户默认好评`这些对我们分析无积极作用的词，这样我们将得到一份具有积极意义的分词列表。


> 最终代码

```python
# -*- coding: utf-8 -*-
import jieba
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import pandas as pd
import os

def read_content(df):
    w_contents = []
    h_contents = []
    for i in range(len(df)):
        w_con = str(df["问题内容"][i])
        h_con = str(df["回答内容"][i])
        print("问题内容",w_con)
        print("回答内容",h_con)
        w_contents.append(w_con)
        h_contents.append(h_con)
    return {'w_contents': w_contents,'h_contents':h_contents}


def wordCloudShow(contents,index,stopwords,font):

    contents_after_split = jieba.cut(str(contents), cut_all=False)  # 准确分词
    words = ' '.join([i for i in contents_after_split if len(i) >= 2])
    STOPWORDS = set(map(str.strip, open(stopwords,encoding="utf-8").readlines()))
    bg_image = plt.imread(f'../pic/1.jpg')
    wc = WordCloud(background_color='white',
                   mask=bg_image,
                   font_path=font,
                   stopwords=STOPWORDS,
                   max_font_size=200,
                   random_state=100)

    wc.generate_from_text(words)
    plt.imshow(wc)
    plt.axis('off')  
    plt.show()
    wc.to_file(f'{index}.jpg')


f = pd.ExcelFile('问大家词频统计.xlsx')
 
data = pd.DataFrame()
for i in f.sheet_names:
    df = pd.read_excel('问大家词频统计.xlsx', sheet_name=i)
    print(i.split('｜')[-1])
    content_dict = read_content(df)
    wordCloudShow(content_dict['w_contents'], i.split('｜')[-1], "./stopwords", "./msyhbd.ttf")
```
