> 我还是认为有必要谈一谈 `定时任务`, 它在日常工作中太常见了。

## Celery - 分布式任务队列

`celery` 是一个非常强大 `python` 第三方任务队列。

运用于日常任务的生产和消费，以及后台`定时任务`。

用官方文档的原话说 ，Celery 是一个简单，灵活，可靠的分布式系统，用于处理大量消息，同时为操作提供维护此类系统所需的工具。

它是一个任务队列，专注于实时处理，同时还支持任务调度。

Celery 是用 Python 编写的，但协议可以用任何语言实现。

除了 Python 之外，还有 Node.js 和 PHP 客户端。


## 生产者消费者模式
### Celery的架构

Celery的架构由三部分组成，消息中间件（message broker），任务执行单元（worker）和任务执行结果存储（task result store）组成。

### 消息中间件

celery消息中间件，也就是所谓的中间人，官方支持的两种稳定的消息队列数据库，一个是RabbitMQ，另一个 Redis。当然选用其他数据库也是可行的，比如, MongoDB 等，用的比较多的当然就是高性能Redis数据库啦，当然MQ也同样强大。 Worker 进程会持续监视队列中是否有需要处理的新任务(如果有就消费，没有则持续监听队列)

### 任务执行单元

Worker 是 Celery 提供的任务执行的单元，Worker 并发的运行在分布式的系统节点中，也就是充当了任务工人的角色(消费者)，用于系统调度。

在开启中间消息队列之后，任务单元会监听消息队列并从中间件里消费任务，执行任务单元，将结果存入后端数据库。

### 任务结果存储

Celery 支持以不同方式存储任务的结果，后端存储包括 Redis，MongoDB，Mysql 等等。

## 安装

```python
pip install celery
pip install redis
```


## 基础用法

### 编写任务

这里我们编写 2 个方法(加和减)，通过 装饰器注册为 celery 任务。

```python
# tasks.py
from celery import Celery

celery_app = Celery('my_task', broker='redis://localhost:6379/0')

@celery_app.task
def add(x, y):
    print("等待 20 s .... done")
    time.sleep(20)  # 模拟耗时操作
    return x + y

@celery_app.task
def mu(x, y):
    print("等待 5 s .... done")
    time.sleep(5)  # 模拟耗时操作
    return x - y

```

### 启动 worker
```python
celery -A tasks worker -l info -c 2  -P eventlet
celery -A tasks beat -l info
```

现在很困、不想写了。


### 发布任务

### 消费任务

### 定时任务
